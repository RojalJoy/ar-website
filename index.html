<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simple AR Example with AI Integration</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
        }
    </style>
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.module.js",
                "three/examples/jsm/loaders/GLTFLoader.js": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/loaders/GLTFLoader.js",
                "three/examples/jsm/webxr/ARButton.js": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/webxr/ARButton.js"
            }
        }
    </script>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@webxr-input-profiles/motion-controllers@1.0.0"></script>
    <script type="module">
        import * as THREE from 'three';
        import { ARButton } from 'three/examples/jsm/webxr/ARButton.js';
        import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';

        let camera, scene, renderer, mixer;

        init();
        animate();
        initAudio();

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 1000);

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            document.body.appendChild(renderer.domElement);

            const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
            light.position.set(0.5, 1, 0.25);
            scene.add(light);

            document.body.appendChild(ARButton.createButton(renderer));

            const loader = new GLTFLoader();
            loader.load('scene.gltf', function(gltf) {
                const model = gltf.scene;
                model.scale.set(0.05, 0.05, 0.05);
                model.position.set(0, -0.1, -0.25);
                scene.add(model);

                mixer = new THREE.AnimationMixer(model);
                const clips = gltf.animations;
                if (clips && clips.length > 0) {
                    clips.forEach(clip => mixer.clipAction(clip).play());
                }
            }, undefined, function(error) {
                console.error(error);
            });

            window.addEventListener('resize', onWindowResize, false);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            renderer.setAnimationLoop(render);
        }

        function render() {
            if (mixer) {
                mixer.update(0.01); // Update the animation mixer, adjusting the time as needed
            }
            renderer.render(scene, camera);
        }

        // Initialize audio capture
        function initAudio() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                console.log('getUserMedia supported.');

                const constraints = { audio: true };
                let chunks = [];

                navigator.mediaDevices.getUserMedia(constraints)
                    .then(function(stream) {
                        const mediaRecorder = new MediaRecorder(stream);

                        mediaRecorder.onstart = function(e) {
                            console.log('Recording started');
                        }

                        mediaRecorder.onstop = function(e) {
                            console.log('Recording stopped');
                            const blob = new Blob(chunks, { 'type': 'audio/ogg; codecs=opus' });
                            chunks = [];
                            const audioURL = URL.createObjectURL(blob);
                            sendAudioToAI(audioURL);
                        }

                        mediaRecorder.ondataavailable = function(e) {
                            chunks.push(e.data);
                        }

                        document.body.addEventListener('click', () => {
                            if (mediaRecorder.state === 'inactive') {
                                mediaRecorder.start();
                                setTimeout(() => {
                                    mediaRecorder.stop();
                                }, 5000); // Record for 5 seconds
                            }
                        });
                    })
                    .catch(function(err) {
                        console.error('The following getUserMedia error occurred: ' + err);
                    });
            } else {
                console.error('getUserMedia not supported on your browser!');
            }
        }

        function sendAudioToAI(audioURL) {
            fetch(audioURL)
                .then(response => response.blob())
                .then(blob => {
                    const formData = new FormData();
                    formData.append('file', blob, 'audio.ogg');

                    fetch('/process_audio', {
                        method: 'POST',
                        body: formData
                    })
                    .then(response => response.json())
                    .then(data => {
                        console.log('AI Response:', data);
                        if (data.text) {
                            textToSpeech(data.text);
                        }
                    })
                    .catch(error => {
                        console.error('Error sending audio to AI:', error);
                    });
                });
        }

        function textToSpeech(text) {
            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
        }
    </script>
</body>
</html>
