<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simple AR Example with Placement and Speech</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
        }
    </style>
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.module.js",
                "three/examples/jsm/loaders/GLTFLoader.js": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/loaders/GLTFLoader.js",
                "three/examples/jsm/webxr/ARButton.js": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/webxr/ARButton.js"
            }
        }
    </script>
</head>
<body>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@webxr-input-profiles/motion-controllers@1.0.0"></script>
    <script type="module">
        import * as THREE from 'three';
        import { ARButton } from 'three/examples/jsm/webxr/ARButton.js';
        import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';

        let camera, scene, renderer, mixer, model;

        init();
        animate();

        function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 1000);

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.xr.enabled = true;
            document.body.appendChild(renderer.domElement);

            const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
            light.position.set(0.5, 1, 0.25);
            scene.add(light);

            document.body.appendChild(ARButton.createButton(renderer));

            const loader = new GLTFLoader();
            loader.load('scene.gltf', function(gltf) {
                model = gltf.scene;
                model.scale.set(0.05, 0.05, 0.05);
                scene.add(model);

                mixer = new THREE.AnimationMixer(model);
                const clips = gltf.animations;
                if (clips && clips.length > 0) {
                    clips.forEach(clip => mixer.clipAction(clip).play());
                }

                // Trigger speech synthesis
                speak("Hello! I am your AR model speaking to you.");
            }, undefined, function(error) {
                console.error(error);
            });

            window.addEventListener('resize', onWindowResize, false);
            window.addEventListener('click', onClick, false);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function onClick(event) {
            // Convert screen coordinates to normalized device coordinates (-1 to +1)
            const x = (event.clientX / window.innerWidth) * 2 - 1;
            const y = -(event.clientY / window.innerHeight) * 2 + 1;

            // Use raycasting to place the model
            const raycaster = new THREE.Raycaster();
            raycaster.setFromCamera(new THREE.Vector2(x, y), camera);
            const intersects = raycaster.intersectObject(scene, true);

            if (intersects.length > 0) {
                const intersect = intersects[0];
                model.position.copy(intersect.point);
            }
        }

        function animate() {
            renderer.setAnimationLoop(render);
        }

        function render() {
            if (mixer) {
                mixer.update(0.01); // Update the animation mixer, adjusting the time as needed
            }
            renderer.render(scene, camera);
        }

        // Function to trigger speech synthesis
        function speak(text) {
            const synth = window.speechSynthesis;
            const utterThis = new SpeechSynthesisUtterance(text);
            synth.speak(utterThis);
        }
    </script>
</body>
</html>
